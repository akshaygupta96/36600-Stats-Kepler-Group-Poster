---
title: "Kepler Group Poster Project"
author: "Sashank Yalavarthy, Javier Abollado, Marius Nwobi, Erick Cohen. Alekhya Vittalam, Akshay Gupta"
date: "2024-11-27"
output: html_document
---

Dataset info: https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html

```{r setup, include=FALSE}
suppressMessages(library(dplyr))
suppressMessages(library(tidyr))
suppressMessages(library(ggplot2))
suppressMessages(library(randomForest))
```

# Read data 


```{r}
set.seed(101)
df <- read.csv('data/kepler.csv', stringsAsFactors = TRUE)
dim(df)
summary(df)
```

## Check Nan values

```{r}
colSums(is.na(df))
```

there are none.

## Check data distribution

```{r}
df %>% select(-label) %>%
  gather(key = "variable", value = "value") %>%
  ggplot(aes(x = value)) +
  facet_wrap(~ variable, scales = "free") +
  geom_histogram(bins = 30, color = "black", fill = "skyblue") +
  labs(title = "Histograms of features")
```

```{r}
df %>%
  gather(key = "variable", value = "value", -label) %>%
  ggplot(aes(x = label, y = value)) +
  facet_wrap(~ variable, scales = "free") +
  geom_boxplot()
```

**Note:** our data is extremely skewed. 

```{r}
# Plot bar chart for target
df %>% select(label) %>%
  gather(key = "variable", value = "value") %>%
  ggplot(aes(x = value, fill = variable)) +
  facet_wrap(~ variable, scales = "free") +
  geom_bar(color = "black") +
  labs(title = "Target values") +
  theme(legend.position = "none")
```

# Pipeline for results

```{r}

TABLE <- list(
  model_name = c(),
  accuracy = c(), 
  precision = c(), 
  recall = c(), 
  f1 = c()
)

get_scores <- function(true, pred){
  # Confusion matrix components
  tp <- sum(pred == 1 & true == 1)  # True Positives
  tn <- sum(pred == 0 & true == 0)  # True Negatives
  fp <- sum(pred == 1 & true == 0)  # False Positives
  fn <- sum(pred == 0 & true == 1)  # False Negatives
  
  # Metrics
  accuracy <- (tp + tn) / length(true)
  precision <- tp / (tp + fp)
  recall <- tp / (tp + fn)
  f1 <- 2 * (precision * recall) / (precision + recall)
  
  # Print results
  cat("Accuracy:", accuracy, "\n")
  cat("Precision:", precision, "\n")
  cat("Recall:", recall, "\n")
  cat("F1-score:", f1, "\n")
  return (c(accuracy, precision, recall, f1))
}

save_scores <- function(model_name, results){
  TABLE$model_name <<- c(TABLE$model_name, model_name)
  TABLE$accuracy <<- c(TABLE$accuracy, results[1])
  TABLE$precision <<- c(TABLE$precision, results[2])
  TABLE$recall <<- c(TABLE$recall, results[3])
  TABLE$f1 <<- c(TABLE$f1, results[4])
}

see <- function(){
  return (data.frame(TABLE))
}
```

# Modeling

```{r}
set.seed(42)
s <- sample(seq_len(nrow(df)), size = as.integer(0.7*nrow(df)))

# Train-Test Split
df$label <- factor(ifelse(df$label == "CONFIRMED", 1, 0))
df.train <- df[s, ]
df.test <- df[-s, ]
```

## Logistic Regression

```{r}
lg_model <- glm(label ~ ., data = df.train, family = "binomial")

prob <- as.numeric(predict(lg_model, df.test))
pred <- ifelse(prob > 0.5, 1, 0)
results <- get_scores(df.test$label, pred)
save_scores("Logistic Regression", results)
```

## Random Forest

```{r}
set.seed(42)

rf_model <- randomForest(label ~ ., data = df.train)

prob <- as.numeric(predict(rf_model, df.test, type = "prob")[,2])
pred <- ifelse(prob > 0.5, 1, 0)

results <- get_scores(df.test$label, pred)
save_scores("Random Forest", results)
```



# Summary of diferent models

```{r}
see()
```







